// data files, each row represents an instance.
provider = "csvReader"   // csvReader or mySQLDB

csvReader {
  dataFile = "src/test/resources/testset1.csv"
  dataFilesHaveHeader = true
  // Separator used in the data files as string
  separator = ","
  // quoteCharacter =
  // escxapeCharacter
}

outputFile = "result"   // name only, no extension
outputFormat = "txt"   // "txt" or "json"

// minimal quality
minimalQuality = 0.0
// minimal generality
minGenerality = 0.0
// minimal probability
minProbability = 0.0

maxNumberOfItems = 100

// if true, the closure of the k best subgroups are computed.
computeClosureOfSubgroups = false
// if true, the refinements of subgroups are computed.
refineSubgroups = false

// Supported quality functions are presently Piatetsky (Default),Binomial, Split, Pearson, and Gini
qualityfunction = "Piatetsky"

// List of features
features = [
  {name = "label", typ = "Nominal"},
  {name = "seqId", typ = "Nominal"},
  {name = "ts", typ = "Date"},
  {name = "x", typ = "Nominal"},
  {name = "num", typ = "Numerical"}
]

// name of the target attribute
// all values of the target feature not listed in "groups" are subsumed to a group "default".
target {
  name = "label",
  labels = ["TARGET"]
}

dateTimeFormat = "ss"

time {
  name = ts
}

derivedFeatures {
  aggregators = [
    {
      aggregationField = xxx
      seqId = seqId,
      attributes = [num, x],
      operator = COUNT,
      existsOnly = true,
      condition = {op = ge, arg = 0},
      timeframes = [1s]
    },
    {
      aggregationField = yyy
      seqId = seqId,
      attribute = num,
      operator = SUM,
      existsOnly = false,
      condition = {op = ge, arg = 0.0},
      timeframes = [3s]
      binning = {mode = "Entropy", bins = 5}
    }
  ]
}

// If true, overlapping intervals are generated and used in case of numerical values.
useOverlappingIntervals = false